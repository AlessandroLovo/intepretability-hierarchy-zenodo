run_id = '4'

Running on machine: epyc2

Non default parameters:
{
    "regularization": "gradient",
    "reg_c": 1
}
No transfer learning




k_fold_cross_val:
	Models will be trained from scratch
	=============
	fold 0 (1/5)
	=============
	k_fold_cross_val_split:
	k_fold_cross_val_split: completed in 1.5 s
	normalize_X:
		0.0000\% of the data have non zero std below 1e-4
		saving to: ./R4--reg_c__1--regularization__gradient/fold_0/X_mean.npy and ./R4--reg_c__1--regularization__gradient/fold_0/X_std.npy
	normalize_X: completed in 5.6 s
	normalize_X:
		loading from: ./R4--reg_c__1--regularization__gradient/fold_0/X_mean.npy and ./R4--reg_c__1--regularization__gradient/fold_0/X_std.npy
	normalize_X: completed in 0.6 s
	after normalization: X_tr.shape = (5056, 95, 288, 2), X_va.shape = (1264, 95, 288, 2), Y_tr.shape = (5056,), Y_va.shape = (1264,)
	 time_start = 31, time_end = 123, leftmargin = None, rightmargin = None, T = 14
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	After margin removal: X_tr.shape = (5056, 95, 288, 2), X_va.shape = (1264, 95, 288, 2), Y_tr.shape = (5056,), Y_va.shape = (1264,)
	number of training data: 5056 of which 5237.888951040013 negative and -181.8889510400129 positive
	dense args = [['relu', 'relu', None], [False, False, False], [0.00426, 0.00426, 0.00426]]
	
	Model: "sequential_1"
	_________________________________________________________________
	 Layer (type)                Output Shape              Param #   
	=================================================================
	 sequential (Sequential)     (None, 2)                 55058     
	                                                                 
	 Sigma_Activation (Sigma_Act  (None, 2)                0         
	 ivation)                                                        
	                                                                 
	=================================================================
	Total params: 55,058
	Trainable params: 55,058
	Non-trainable params: 0
	_________________________________________________________________
	
	Using CRPS loss
	train_model:
		scheduler_kwargs = {'lr': 0.0020116, 'epoch_tol': 7, 'warmup': False, 'lr_min': 0.0008463, 'decay': 0.05153}
		Converting training data to tensors
		Converting validation data to tensors
		Training the network on 5056 datapoint and validating on 1264
		
		Learning rate for epoch 1 is 0.002011599950492382
		
		Learning rate for epoch 2 is 0.002011599950492382
		
		Learning rate for epoch 3 is 0.002011599950492382
		
		Learning rate for epoch 4 is 0.002011599950492382
		
		Learning rate for epoch 5 is 0.002011599950492382
		
		Learning rate for epoch 6 is 0.002011599950492382
		
		Learning rate for epoch 7 is 0.002011599950492382
		
		Learning rate for epoch 8 is 0.0019105675164610147
		
		Learning rate for epoch 9 is 0.0018146097427234054
		
		Learning rate for epoch 10 is 0.0017234712140634656
		
		Learning rate for epoch 11 is 0.0016369102522730827
		
		Learning rate for epoch 12 is 0.0015546964714303613
		
		Learning rate for epoch 13 is 0.0014766122912988067
		
		Learning rate for epoch 14 is 0.0014024494448676705
		
		Learning rate for epoch 15 is 0.0013320116559043527
		
		Learning rate for epoch 16 is 0.0012651117285713553
		
		Learning rate for epoch 17 is 0.0012015716638416052
		
		Learning rate for epoch 18 is 0.0011412228923290968
		
		Learning rate for epoch 19 is 0.0010839051101356745
		
		Learning rate for epoch 20 is 0.0010294661624357104
		
		Learning rate for epoch 21 is 0.0009777614613994956
		
		Learning rate for epoch 22 is 0.0009286535205319524
		
		Learning rate for epoch 23 is 0.0008820120128802955
		
		Learning rate for epoch 24 is 0.0008462999830953777
		
		Learning rate for epoch 25 is 0.0008462999830953777
		
		Learning rate for epoch 26 is 0.0008462999830953777
		
		Learning rate for epoch 27 is 0.0008462999830953777
		
		Learning rate for epoch 28 is 0.0008462999830953777
		
		Learning rate for epoch 29 is 0.0008462999830953777
		
		Learning rate for epoch 30 is 0.0008462999830953777
		
		Learning rate for epoch 31 is 0.0008462999830953777
		
		Learning rate for epoch 32 is 0.0008462999830953777
		
		Learning rate for epoch 33 is 0.0008462999830953777
		
		Learning rate for epoch 34 is 0.0008462999830953777
		
		Learning rate for epoch 35 is 0.0008462999830953777
		
		Learning rate for epoch 36 is 0.0008462999830953777
		
		Learning rate for epoch 37 is 0.0008462999830953777
		
		Learning rate for epoch 38 is 0.0008462999830953777
		
		Learning rate for epoch 39 is 0.0008462999830953777
		
		Learning rate for epoch 40 is 0.0008462999830953777
		
		Learning rate for epoch 41 is 0.0008462999830953777
		
		Learning rate for epoch 42 is 0.0008462999830953777
		
		Learning rate for epoch 43 is 0.0008462999830953777
		
		Learning rate for epoch 44 is 0.0008462999830953777
		
		Learning rate for epoch 45 is 0.0008462999830953777
		
		Learning rate for epoch 46 is 0.0008462999830953777
		
		Learning rate for epoch 47 is 0.0008462999830953777
		
		Learning rate for epoch 48 is 0.0008462999830953777
		
		Learning rate for epoch 49 is 0.0008462999830953777
		
		Learning rate for epoch 50 is 0.0008462999830953777
		
		Learning rate for epoch 51 is 0.0008462999830953777
		
		Learning rate for epoch 52 is 0.0008462999830953777
		
		Learning rate for epoch 53 is 0.0008462999830953777
		
		Learning rate for epoch 54 is 0.0008462999830953777
		
		Learning rate for epoch 55 is 0.0008462999830953777
		
		Learning rate for epoch 56 is 0.0008462999830953777
		
		Learning rate for epoch 57 is 0.0008462999830953777
		
		Learning rate for epoch 58 is 0.0008462999830953777
		
		Learning rate for epoch 59 is 0.0008462999830953777
		
		Learning rate for epoch 60 is 0.0008462999830953777
		
		Learning rate for epoch 61 is 0.0008462999830953777
		
		Learning rate for epoch 62 is 0.0008462999830953777
		
		Learning rate for epoch 63 is 0.0008462999830953777
		
		Learning rate for epoch 64 is 0.0008462999830953777
		
		Learning rate for epoch 65 is 0.0008462999830953777
		
		Learning rate for epoch 66 is 0.0008462999830953777
		
		Learning rate for epoch 67 is 0.0008462999830953777
		               loss  ParametricCrossEntropyLoss  ...  val_CRPS        lr
		epoch-1                                          ...                    
		0        717.373413                    0.770944  ...  1.071723  0.002012
		1        247.956161                    0.470295  ...  1.030051  0.002012
		2         92.734657                    0.365787  ...  1.025404  0.002012
		3         40.504192                    0.334266  ...  1.017171  0.002012
		4         20.564615                    0.317658  ...  1.009900  0.002012
		...             ...                         ...  ...       ...       ...
		62         0.812497                    0.158700  ...  0.826149  0.000846
		63         0.808433                    0.158853  ...  0.819683  0.000846
		64         0.805408                    0.156566  ...  0.830385  0.000846
		65         0.803556                    0.156842  ...  0.832210  0.000846
		66         0.801515                    0.156844  ...  0.824951  0.000846
		
		[67 rows x 9 columns]
		score = 0.1466471552848816
	train_model: completed in 1 min 15.9 s
	RAM memory: 3.213e+10
	=============
	fold 1 (2/5)
	=============
	k_fold_cross_val_split:
	k_fold_cross_val_split: completed in 1.2 s
	normalize_X:
		0.0000\% of the data have non zero std below 1e-4
		saving to: ./R4--reg_c__1--regularization__gradient/fold_1/X_mean.npy and ./R4--reg_c__1--regularization__gradient/fold_1/X_std.npy
	normalize_X: completed in 5.7 s
	normalize_X:
		loading from: ./R4--reg_c__1--regularization__gradient/fold_1/X_mean.npy and ./R4--reg_c__1--regularization__gradient/fold_1/X_std.npy
	normalize_X: completed in 0.3 s
	after normalization: X_tr.shape = (5056, 95, 288, 2), X_va.shape = (1264, 95, 288, 2), Y_tr.shape = (5056,), Y_va.shape = (1264,)
	 time_start = 31, time_end = 123, leftmargin = None, rightmargin = None, T = 14
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	After margin removal: X_tr.shape = (5056, 95, 288, 2), X_va.shape = (1264, 95, 288, 2), Y_tr.shape = (5056,), Y_va.shape = (1264,)
	number of training data: 5056 of which 5330.196425155069 negative and -274.1964251550694 positive
	dense args = [['relu', 'relu', None], [False, False, False], [0.00426, 0.00426, 0.00426]]
	
	Model: "sequential_1"
	_________________________________________________________________
	 Layer (type)                Output Shape              Param #   
	=================================================================
	 sequential (Sequential)     (None, 2)                 55058     
	                                                                 
	 Sigma_Activation (Sigma_Act  (None, 2)                0         
	 ivation)                                                        
	                                                                 
	=================================================================
	Total params: 55,058
	Trainable params: 55,058
	Non-trainable params: 0
	_________________________________________________________________
	
	Using CRPS loss
	train_model:
		scheduler_kwargs = {'lr': 0.0020116, 'epoch_tol': 7, 'warmup': False, 'lr_min': 0.0008463, 'decay': 0.05153}
		Converting training data to tensors
		Converting validation data to tensors
		Training the network on 5056 datapoint and validating on 1264
		
		Learning rate for epoch 1 is 0.002011599950492382
		
		Learning rate for epoch 2 is 0.002011599950492382
		
		Learning rate for epoch 3 is 0.002011599950492382
		
		Learning rate for epoch 4 is 0.002011599950492382
		
		Learning rate for epoch 5 is 0.002011599950492382
		
		Learning rate for epoch 6 is 0.002011599950492382
		
		Learning rate for epoch 7 is 0.002011599950492382
		
		Learning rate for epoch 8 is 0.0019105675164610147
		
		Learning rate for epoch 9 is 0.0018146097427234054
		
		Learning rate for epoch 10 is 0.0017234712140634656
		
		Learning rate for epoch 11 is 0.0016369102522730827
		
		Learning rate for epoch 12 is 0.0015546964714303613
		
		Learning rate for epoch 13 is 0.0014766122912988067
		
		Learning rate for epoch 14 is 0.0014024494448676705
		
		Learning rate for epoch 15 is 0.0013320116559043527
		
		Learning rate for epoch 16 is 0.0012651117285713553
		
		Learning rate for epoch 17 is 0.0012015716638416052
		
		Learning rate for epoch 18 is 0.0011412228923290968
		
		Learning rate for epoch 19 is 0.0010839051101356745
		
		Learning rate for epoch 20 is 0.0010294661624357104
		
		Learning rate for epoch 21 is 0.0009777614613994956
		
		Learning rate for epoch 22 is 0.0009286535205319524
		
		Learning rate for epoch 23 is 0.0008820120128802955
		
		Learning rate for epoch 24 is 0.0008462999830953777
		
		Learning rate for epoch 25 is 0.0008462999830953777
		
		Learning rate for epoch 26 is 0.0008462999830953777
		
		Learning rate for epoch 27 is 0.0008462999830953777
		
		Learning rate for epoch 28 is 0.0008462999830953777
		
		Learning rate for epoch 29 is 0.0008462999830953777
		
		Learning rate for epoch 30 is 0.0008462999830953777
		
		Learning rate for epoch 31 is 0.0008462999830953777
		
		Learning rate for epoch 32 is 0.0008462999830953777
		
		Learning rate for epoch 33 is 0.0008462999830953777
		
		Learning rate for epoch 34 is 0.0008462999830953777
		
		Learning rate for epoch 35 is 0.0008462999830953777
		
		Learning rate for epoch 36 is 0.0008462999830953777
		
		Learning rate for epoch 37 is 0.0008462999830953777
		
		Learning rate for epoch 38 is 0.0008462999830953777
		
		Learning rate for epoch 39 is 0.0008462999830953777
		
		Learning rate for epoch 40 is 0.0008462999830953777
		
		Learning rate for epoch 41 is 0.0008462999830953777
		
		Learning rate for epoch 42 is 0.0008462999830953777
		
		Learning rate for epoch 43 is 0.0008462999830953777
		
		Learning rate for epoch 44 is 0.0008462999830953777
		
		Learning rate for epoch 45 is 0.0008462999830953777
		
		Learning rate for epoch 46 is 0.0008462999830953777
		
		Learning rate for epoch 47 is 0.0008462999830953777
		
		Learning rate for epoch 48 is 0.0008462999830953777
		
		Learning rate for epoch 49 is 0.0008462999830953777
		
		Learning rate for epoch 50 is 0.0008462999830953777
		
		Learning rate for epoch 51 is 0.0008462999830953777
		
		Learning rate for epoch 52 is 0.0008462999830953777
		
		Learning rate for epoch 53 is 0.0008462999830953777
		
		Learning rate for epoch 54 is 0.0008462999830953777
		
		Learning rate for epoch 55 is 0.0008462999830953777
		
		Learning rate for epoch 56 is 0.0008462999830953777
		
		Learning rate for epoch 57 is 0.0008462999830953777
		
		Learning rate for epoch 58 is 0.0008462999830953777
		
		Learning rate for epoch 59 is 0.0008462999830953777
		
		Learning rate for epoch 60 is 0.0008462999830953777
		
		Learning rate for epoch 61 is 0.0008462999830953777
		
		Learning rate for epoch 62 is 0.0008462999830953777
		
		Learning rate for epoch 63 is 0.0008462999830953777
		
		Learning rate for epoch 64 is 0.0008462999830953777
		
		Learning rate for epoch 65 is 0.0008462999830953777
		               loss  ParametricCrossEntropyLoss  ...  val_CRPS        lr
		epoch-1                                          ...                    
		0        727.013733                    0.652864  ...  1.148179  0.002012
		1        248.784363                    0.368799  ...  0.937022  0.002012
		2         91.806648                    0.308126  ...  0.878082  0.002012
		3         39.583694                    0.259260  ...  0.846712  0.002012
		4         19.826117                    0.229949  ...  0.827899  0.002012
		...             ...                         ...  ...       ...       ...
		60         0.824712                    0.158412  ...  0.780567  0.000846
		61         0.824124                    0.160465  ...  0.778867  0.000846
		62         0.821329                    0.158801  ...  0.785451  0.000846
		63         0.816703                    0.158066  ...  0.787516  0.000846
		64         0.814795                    0.156045  ...  0.777153  0.000846
		
		[65 rows x 9 columns]
		score = 0.14995507895946503
	train_model: completed in 1 min 11.0 s
	RAM memory: 3.192e+10
	=============
	fold 2 (3/5)
	=============
	k_fold_cross_val_split:
	k_fold_cross_val_split: completed in 1.7 s
	normalize_X:
		0.0000\% of the data have non zero std below 1e-4
		saving to: ./R4--reg_c__1--regularization__gradient/fold_2/X_mean.npy and ./R4--reg_c__1--regularization__gradient/fold_2/X_std.npy
	normalize_X: completed in 5.6 s
	normalize_X:
		loading from: ./R4--reg_c__1--regularization__gradient/fold_2/X_mean.npy and ./R4--reg_c__1--regularization__gradient/fold_2/X_std.npy
	normalize_X: completed in 0.9 s
	after normalization: X_tr.shape = (5056, 95, 288, 2), X_va.shape = (1264, 95, 288, 2), Y_tr.shape = (5056,), Y_va.shape = (1264,)
	 time_start = 31, time_end = 123, leftmargin = None, rightmargin = None, T = 14
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	After margin removal: X_tr.shape = (5056, 95, 288, 2), X_va.shape = (1264, 95, 288, 2), Y_tr.shape = (5056,), Y_va.shape = (1264,)
	number of training data: 5056 of which 4685.531996924793 negative and 370.4680030752073 positive
	dense args = [['relu', 'relu', None], [False, False, False], [0.00426, 0.00426, 0.00426]]
	
	Model: "sequential_1"
	_________________________________________________________________
	 Layer (type)                Output Shape              Param #   
	=================================================================
	 sequential (Sequential)     (None, 2)                 55058     
	                                                                 
	 Sigma_Activation (Sigma_Act  (None, 2)                0         
	 ivation)                                                        
	                                                                 
	=================================================================
	Total params: 55,058
	Trainable params: 55,058
	Non-trainable params: 0
	_________________________________________________________________
	
	Using CRPS loss
	train_model:
		scheduler_kwargs = {'lr': 0.0020116, 'epoch_tol': 7, 'warmup': False, 'lr_min': 0.0008463, 'decay': 0.05153}
		Converting training data to tensors
		Converting validation data to tensors
		Training the network on 5056 datapoint and validating on 1264
		
		Learning rate for epoch 1 is 0.002011599950492382
		
		Learning rate for epoch 2 is 0.002011599950492382
		
		Learning rate for epoch 3 is 0.002011599950492382
		
		Learning rate for epoch 4 is 0.002011599950492382
		
		Learning rate for epoch 5 is 0.002011599950492382
		
		Learning rate for epoch 6 is 0.002011599950492382
		
		Learning rate for epoch 7 is 0.002011599950492382
		
		Learning rate for epoch 8 is 0.0019105675164610147
		
		Learning rate for epoch 9 is 0.0018146097427234054
		
		Learning rate for epoch 10 is 0.0017234712140634656
		
		Learning rate for epoch 11 is 0.0016369102522730827
		
		Learning rate for epoch 12 is 0.0015546964714303613
		
		Learning rate for epoch 13 is 0.0014766122912988067
		
		Learning rate for epoch 14 is 0.0014024494448676705
		
		Learning rate for epoch 15 is 0.0013320116559043527
		
		Learning rate for epoch 16 is 0.0012651117285713553
		
		Learning rate for epoch 17 is 0.0012015716638416052
		
		Learning rate for epoch 18 is 0.0011412228923290968
		
		Learning rate for epoch 19 is 0.0010839051101356745
		
		Learning rate for epoch 20 is 0.0010294661624357104
		
		Learning rate for epoch 21 is 0.0009777614613994956
		
		Learning rate for epoch 22 is 0.0009286535205319524
		
		Learning rate for epoch 23 is 0.0008820120128802955
		
		Learning rate for epoch 24 is 0.0008462999830953777
		
		Learning rate for epoch 25 is 0.0008462999830953777
		
		Learning rate for epoch 26 is 0.0008462999830953777
		
		Learning rate for epoch 27 is 0.0008462999830953777
		
		Learning rate for epoch 28 is 0.0008462999830953777
		
		Learning rate for epoch 29 is 0.0008462999830953777
		
		Learning rate for epoch 30 is 0.0008462999830953777
		
		Learning rate for epoch 31 is 0.0008462999830953777
		
		Learning rate for epoch 32 is 0.0008462999830953777
		
		Learning rate for epoch 33 is 0.0008462999830953777
		
		Learning rate for epoch 34 is 0.0008462999830953777
		
		Learning rate for epoch 35 is 0.0008462999830953777
		
		Learning rate for epoch 36 is 0.0008462999830953777
		
		Learning rate for epoch 37 is 0.0008462999830953777
		
		Learning rate for epoch 38 is 0.0008462999830953777
		
		Learning rate for epoch 39 is 0.0008462999830953777
		
		Learning rate for epoch 40 is 0.0008462999830953777
		
		Learning rate for epoch 41 is 0.0008462999830953777
		
		Learning rate for epoch 42 is 0.0008462999830953777
		
		Learning rate for epoch 43 is 0.0008462999830953777
		
		Learning rate for epoch 44 is 0.0008462999830953777
		
		Learning rate for epoch 45 is 0.0008462999830953777
		
		Learning rate for epoch 46 is 0.0008462999830953777
		
		Learning rate for epoch 47 is 0.0008462999830953777
		
		Learning rate for epoch 48 is 0.0008462999830953777
		
		Learning rate for epoch 49 is 0.0008462999830953777
		
		Learning rate for epoch 50 is 0.0008462999830953777
		
		Learning rate for epoch 51 is 0.0008462999830953777
		
		Learning rate for epoch 52 is 0.0008462999830953777
		
		Learning rate for epoch 53 is 0.0008462999830953777
		
		Learning rate for epoch 54 is 0.0008462999830953777
		
		Learning rate for epoch 55 is 0.0008462999830953777
		
		Learning rate for epoch 56 is 0.0008462999830953777
		
		Learning rate for epoch 57 is 0.0008462999830953777
		
		Learning rate for epoch 58 is 0.0008462999830953777
		
		Learning rate for epoch 59 is 0.0008462999830953777
		
		Learning rate for epoch 60 is 0.0008462999830953777
		
		Learning rate for epoch 61 is 0.0008462999830953777
		
		Learning rate for epoch 62 is 0.0008462999830953777
		
		Learning rate for epoch 63 is 0.0008462999830953777
		
		Learning rate for epoch 64 is 0.0008462999830953777
		
		Learning rate for epoch 65 is 0.0008462999830953777
		
		Learning rate for epoch 66 is 0.0008462999830953777
		
		Learning rate for epoch 67 is 0.0008462999830953777
		
		Learning rate for epoch 68 is 0.0008462999830953777
		
		Learning rate for epoch 69 is 0.0008462999830953777
		
		Learning rate for epoch 70 is 0.0008462999830953777
		
		Learning rate for epoch 71 is 0.0008462999830953777
		
		Learning rate for epoch 72 is 0.0008462999830953777
		
		Learning rate for epoch 73 is 0.0008462999830953777
		
		Learning rate for epoch 74 is 0.0008462999830953777
		
		Learning rate for epoch 75 is 0.0008462999830953777
		
		Learning rate for epoch 76 is 0.0008462999830953777
		               loss  ParametricCrossEntropyLoss  ...  val_CRPS        lr
		epoch-1                                          ...                    
		0        752.800171                    0.362035  ...  1.049025  0.002012
		1        261.433655                    0.320190  ...  1.027133  0.002012
		2         97.943634                    0.320580  ...  1.013955  0.002012
		3         43.009926                    0.310994  ...  1.020577  0.002012
		4         22.043079                    0.294876  ...  1.018276  0.002012
		...             ...                         ...  ...       ...       ...
		71         0.809532                    0.167797  ...  0.778719  0.000846
		72         0.804861                    0.168016  ...  0.783055  0.000846
		73         0.802160                    0.169885  ...  0.775331  0.000846
		74         0.803555                    0.166105  ...  0.775779  0.000846
		75         0.801006                    0.166178  ...  0.784899  0.000846
		
		[76 rows x 9 columns]
		score = 0.1082172617316246
	train_model: completed in 1 min 16.6 s
	RAM memory: 3.221e+10
	=============
	fold 3 (4/5)
	=============
	k_fold_cross_val_split:
	k_fold_cross_val_split: completed in 0.1 s
	normalize_X:
		0.0000\% of the data have non zero std below 1e-4
		saving to: ./R4--reg_c__1--regularization__gradient/fold_3/X_mean.npy and ./R4--reg_c__1--regularization__gradient/fold_3/X_std.npy
	normalize_X: completed in 0.9 s
	normalize_X:
		loading from: ./R4--reg_c__1--regularization__gradient/fold_3/X_mean.npy and ./R4--reg_c__1--regularization__gradient/fold_3/X_std.npy
	normalize_X: completed in 0.1 s
	after normalization: X_tr.shape = (5056, 95, 288, 2), X_va.shape = (1264, 95, 288, 2), Y_tr.shape = (5056,), Y_va.shape = (1264,)
	 time_start = 31, time_end = 123, leftmargin = None, rightmargin = None, T = 14
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	After margin removal: X_tr.shape = (5056, 95, 288, 2), X_va.shape = (1264, 95, 288, 2), Y_tr.shape = (5056,), Y_va.shape = (1264,)
	number of training data: 5056 of which 4759.907159803726 negative and 296.09284019627347 positive
	dense args = [['relu', 'relu', None], [False, False, False], [0.00426, 0.00426, 0.00426]]
	
	Model: "sequential_1"
	_________________________________________________________________
	 Layer (type)                Output Shape              Param #   
	=================================================================
	 sequential (Sequential)     (None, 2)                 55058     
	                                                                 
	 Sigma_Activation (Sigma_Act  (None, 2)                0         
	 ivation)                                                        
	                                                                 
	=================================================================
	Total params: 55,058
	Trainable params: 55,058
	Non-trainable params: 0
	_________________________________________________________________
	
	Using CRPS loss
	train_model:
		scheduler_kwargs = {'lr': 0.0020116, 'epoch_tol': 7, 'warmup': False, 'lr_min': 0.0008463, 'decay': 0.05153}
		Converting training data to tensors
		Converting validation data to tensors
		Training the network on 5056 datapoint and validating on 1264
		
		Learning rate for epoch 1 is 0.002011599950492382
		
		Learning rate for epoch 2 is 0.002011599950492382
		
		Learning rate for epoch 3 is 0.002011599950492382
		
		Learning rate for epoch 4 is 0.002011599950492382
		
		Learning rate for epoch 5 is 0.002011599950492382
		
		Learning rate for epoch 6 is 0.002011599950492382
		
		Learning rate for epoch 7 is 0.002011599950492382
		
		Learning rate for epoch 8 is 0.0019105675164610147
		
		Learning rate for epoch 9 is 0.0018146097427234054
		
		Learning rate for epoch 10 is 0.0017234712140634656
		
		Learning rate for epoch 11 is 0.0016369102522730827
		
		Learning rate for epoch 12 is 0.0015546964714303613
		
		Learning rate for epoch 13 is 0.0014766122912988067
		
		Learning rate for epoch 14 is 0.0014024494448676705
		
		Learning rate for epoch 15 is 0.0013320116559043527
		
		Learning rate for epoch 16 is 0.0012651117285713553
		
		Learning rate for epoch 17 is 0.0012015716638416052
		
		Learning rate for epoch 18 is 0.0011412228923290968
		
		Learning rate for epoch 19 is 0.0010839051101356745
		
		Learning rate for epoch 20 is 0.0010294661624357104
		
		Learning rate for epoch 21 is 0.0009777614613994956
		
		Learning rate for epoch 22 is 0.0009286535205319524
		
		Learning rate for epoch 23 is 0.0008820120128802955
		
		Learning rate for epoch 24 is 0.0008462999830953777
		
		Learning rate for epoch 25 is 0.0008462999830953777
		
		Learning rate for epoch 26 is 0.0008462999830953777
		
		Learning rate for epoch 27 is 0.0008462999830953777
		
		Learning rate for epoch 28 is 0.0008462999830953777
		
		Learning rate for epoch 29 is 0.0008462999830953777
		
		Learning rate for epoch 30 is 0.0008462999830953777
		
		Learning rate for epoch 31 is 0.0008462999830953777
		
		Learning rate for epoch 32 is 0.0008462999830953777
		
		Learning rate for epoch 33 is 0.0008462999830953777
		
		Learning rate for epoch 34 is 0.0008462999830953777
		
		Learning rate for epoch 35 is 0.0008462999830953777
		
		Learning rate for epoch 36 is 0.0008462999830953777
		
		Learning rate for epoch 37 is 0.0008462999830953777
		
		Learning rate for epoch 38 is 0.0008462999830953777
		
		Learning rate for epoch 39 is 0.0008462999830953777
		
		Learning rate for epoch 40 is 0.0008462999830953777
		
		Learning rate for epoch 41 is 0.0008462999830953777
		
		Learning rate for epoch 42 is 0.0008462999830953777
		
		Learning rate for epoch 43 is 0.0008462999830953777
		
		Learning rate for epoch 44 is 0.0008462999830953777
		
		Learning rate for epoch 45 is 0.0008462999830953777
		
		Learning rate for epoch 46 is 0.0008462999830953777
		
		Learning rate for epoch 47 is 0.0008462999830953777
		
		Learning rate for epoch 48 is 0.0008462999830953777
		
		Learning rate for epoch 49 is 0.0008462999830953777
		
		Learning rate for epoch 50 is 0.0008462999830953777
		
		Learning rate for epoch 51 is 0.0008462999830953777
		
		Learning rate for epoch 52 is 0.0008462999830953777
		
		Learning rate for epoch 53 is 0.0008462999830953777
		
		Learning rate for epoch 54 is 0.0008462999830953777
		
		Learning rate for epoch 55 is 0.0008462999830953777
		
		Learning rate for epoch 56 is 0.0008462999830953777
		
		Learning rate for epoch 57 is 0.0008462999830953777
		
		Learning rate for epoch 58 is 0.0008462999830953777
		
		Learning rate for epoch 59 is 0.0008462999830953777
		
		Learning rate for epoch 60 is 0.0008462999830953777
		
		Learning rate for epoch 61 is 0.0008462999830953777
		
		Learning rate for epoch 62 is 0.0008462999830953777
		
		Learning rate for epoch 63 is 0.0008462999830953777
		
		Learning rate for epoch 64 is 0.0008462999830953777
		
		Learning rate for epoch 65 is 0.0008462999830953777
		
		Learning rate for epoch 66 is 0.0008462999830953777
		
		Learning rate for epoch 67 is 0.0008462999830953777
		
		Learning rate for epoch 68 is 0.0008462999830953777
		
		Learning rate for epoch 69 is 0.0008462999830953777
		
		Learning rate for epoch 70 is 0.0008462999830953777
		
		Learning rate for epoch 71 is 0.0008462999830953777
		
		Learning rate for epoch 72 is 0.0008462999830953777
		
		Learning rate for epoch 73 is 0.0008462999830953777
		
		Learning rate for epoch 74 is 0.0008462999830953777
		
		Learning rate for epoch 75 is 0.0008462999830953777
		
		Learning rate for epoch 76 is 0.0008462999830953777
		
		Learning rate for epoch 77 is 0.0008462999830953777
		
		Learning rate for epoch 78 is 0.0008462999830953777
		
		Learning rate for epoch 79 is 0.0008462999830953777
		
		Learning rate for epoch 80 is 0.0008462999830953777
		
		Learning rate for epoch 81 is 0.0008462999830953777
		
		Learning rate for epoch 82 is 0.0008462999830953777
		
		Learning rate for epoch 83 is 0.0008462999830953777
		
		Learning rate for epoch 84 is 0.0008462999830953777
		
		Learning rate for epoch 85 is 0.0008462999830953777
		
		Learning rate for epoch 86 is 0.0008462999830953777
		
		Learning rate for epoch 87 is 0.0008462999830953777
		
		Learning rate for epoch 88 is 0.0008462999830953777
		
		Learning rate for epoch 89 is 0.0008462999830953777
		
		Learning rate for epoch 90 is 0.0008462999830953777
		
		Learning rate for epoch 91 is 0.0008462999830953777
		
		Learning rate for epoch 92 is 0.0008462999830953777
		
		Learning rate for epoch 93 is 0.0008462999830953777
		               loss  ParametricCrossEntropyLoss  ...  val_CRPS        lr
		epoch-1                                          ...                    
		0        734.666260                    0.975086  ...  1.419750  0.002012
		1        254.566055                    0.912123  ...  1.276875  0.002012
		2         95.023209                    0.627993  ...  1.157170  0.002012
		3         41.469757                    0.357291  ...  1.142555  0.002012
		4         21.069063                    0.326193  ...  1.129423  0.002012
		...             ...                         ...  ...       ...       ...
		88         0.786915                    0.158014  ...  0.809594  0.000846
		89         0.784043                    0.156627  ...  0.808468  0.000846
		90         0.783233                    0.158256  ...  0.818563  0.000846
		91         0.783682                    0.156252  ...  0.813333  0.000846
		92         0.784568                    0.157231  ...  0.803016  0.000846
		
		[93 rows x 9 columns]
		score = 0.13993783295154572
	train_model: completed in 1 min 37.0 s
	RAM memory: 3.238e+10
	=============
	fold 4 (5/5)
	=============
	k_fold_cross_val_split:
	k_fold_cross_val_split: completed in 0.1 s
	normalize_X:
		0.0000\% of the data have non zero std below 1e-4
		saving to: ./R4--reg_c__1--regularization__gradient/fold_4/X_mean.npy and ./R4--reg_c__1--regularization__gradient/fold_4/X_std.npy
	normalize_X: completed in 1.1 s
	normalize_X:
		loading from: ./R4--reg_c__1--regularization__gradient/fold_4/X_mean.npy and ./R4--reg_c__1--regularization__gradient/fold_4/X_std.npy
	normalize_X: completed in 0.1 s
	after normalization: X_tr.shape = (5056, 95, 288, 2), X_va.shape = (1264, 95, 288, 2), Y_tr.shape = (5056,), Y_va.shape = (1264,)
	 time_start = 31, time_end = 123, leftmargin = None, rightmargin = None, T = 14
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	margin_removal_with_sliding_window:
	margin_removal_with_sliding_window: completed in 0.0 s
	After margin removal: X_tr.shape = (5056, 95, 288, 2), X_va.shape = (1264, 95, 288, 2), Y_tr.shape = (5056,), Y_va.shape = (1264,)
	number of training data: 5056 of which 4870.109394350927 negative and 185.89060564907294 positive
	dense args = [['relu', 'relu', None], [False, False, False], [0.00426, 0.00426, 0.00426]]
	
	Model: "sequential_1"
	_________________________________________________________________
	 Layer (type)                Output Shape              Param #   
	=================================================================
	 sequential (Sequential)     (None, 2)                 55058     
	                                                                 
	 Sigma_Activation (Sigma_Act  (None, 2)                0         
	 ivation)                                                        
	                                                                 
	=================================================================
	Total params: 55,058
	Trainable params: 55,058
	Non-trainable params: 0
	_________________________________________________________________
	
	Using CRPS loss
	train_model:
		scheduler_kwargs = {'lr': 0.0020116, 'epoch_tol': 7, 'warmup': False, 'lr_min': 0.0008463, 'decay': 0.05153}
		Converting training data to tensors
		Converting validation data to tensors
		Training the network on 5056 datapoint and validating on 1264
		
		Learning rate for epoch 1 is 0.002011599950492382
		
		Learning rate for epoch 2 is 0.002011599950492382
		
		Learning rate for epoch 3 is 0.002011599950492382
		
		Learning rate for epoch 4 is 0.002011599950492382
		
		Learning rate for epoch 5 is 0.002011599950492382
		
		Learning rate for epoch 6 is 0.002011599950492382
		
		Learning rate for epoch 7 is 0.002011599950492382
		
		Learning rate for epoch 8 is 0.0019105675164610147
		
		Learning rate for epoch 9 is 0.0018146097427234054
		
		Learning rate for epoch 10 is 0.0017234712140634656
		
		Learning rate for epoch 11 is 0.0016369102522730827
		
		Learning rate for epoch 12 is 0.0015546964714303613
		
		Learning rate for epoch 13 is 0.0014766122912988067
		
		Learning rate for epoch 14 is 0.0014024494448676705
		
		Learning rate for epoch 15 is 0.0013320116559043527
		
		Learning rate for epoch 16 is 0.0012651117285713553
		
		Learning rate for epoch 17 is 0.0012015716638416052
		
		Learning rate for epoch 18 is 0.0011412228923290968
		
		Learning rate for epoch 19 is 0.0010839051101356745
		
		Learning rate for epoch 20 is 0.0010294661624357104
		
		Learning rate for epoch 21 is 0.0009777614613994956
		
		Learning rate for epoch 22 is 0.0009286535205319524
		
		Learning rate for epoch 23 is 0.0008820120128802955
		
		Learning rate for epoch 24 is 0.0008462999830953777
		
		Learning rate for epoch 25 is 0.0008462999830953777
		
		Learning rate for epoch 26 is 0.0008462999830953777
		
		Learning rate for epoch 27 is 0.0008462999830953777
		
		Learning rate for epoch 28 is 0.0008462999830953777
		
		Learning rate for epoch 29 is 0.0008462999830953777
		
		Learning rate for epoch 30 is 0.0008462999830953777
		
		Learning rate for epoch 31 is 0.0008462999830953777
		
		Learning rate for epoch 32 is 0.0008462999830953777
		
		Learning rate for epoch 33 is 0.0008462999830953777
		
		Learning rate for epoch 34 is 0.0008462999830953777
		
		Learning rate for epoch 35 is 0.0008462999830953777
		
		Learning rate for epoch 36 is 0.0008462999830953777
		
		Learning rate for epoch 37 is 0.0008462999830953777
		
		Learning rate for epoch 38 is 0.0008462999830953777
		
		Learning rate for epoch 39 is 0.0008462999830953777
		
		Learning rate for epoch 40 is 0.0008462999830953777
		
		Learning rate for epoch 41 is 0.0008462999830953777
		
		Learning rate for epoch 42 is 0.0008462999830953777
		
		Learning rate for epoch 43 is 0.0008462999830953777
		
		Learning rate for epoch 44 is 0.0008462999830953777
		
		Learning rate for epoch 45 is 0.0008462999830953777
		
		Learning rate for epoch 46 is 0.0008462999830953777
		
		Learning rate for epoch 47 is 0.0008462999830953777
		
		Learning rate for epoch 48 is 0.0008462999830953777
		
		Learning rate for epoch 49 is 0.0008462999830953777
		
		Learning rate for epoch 50 is 0.0008462999830953777
		
		Learning rate for epoch 51 is 0.0008462999830953777
		
		Learning rate for epoch 52 is 0.0008462999830953777
		
		Learning rate for epoch 53 is 0.0008462999830953777
		
		Learning rate for epoch 54 is 0.0008462999830953777
		
		Learning rate for epoch 55 is 0.0008462999830953777
		
		Learning rate for epoch 56 is 0.0008462999830953777
		
		Learning rate for epoch 57 is 0.0008462999830953777
		
		Learning rate for epoch 58 is 0.0008462999830953777
		
		Learning rate for epoch 59 is 0.0008462999830953777
		
		Learning rate for epoch 60 is 0.0008462999830953777
		
		Learning rate for epoch 61 is 0.0008462999830953777
		
		Learning rate for epoch 62 is 0.0008462999830953777
		
		Learning rate for epoch 63 is 0.0008462999830953777
		
		Learning rate for epoch 64 is 0.0008462999830953777
		
		Learning rate for epoch 65 is 0.0008462999830953777
		
		Learning rate for epoch 66 is 0.0008462999830953777
		
		Learning rate for epoch 67 is 0.0008462999830953777
		
		Learning rate for epoch 68 is 0.0008462999830953777
		
		Learning rate for epoch 69 is 0.0008462999830953777
		
		Learning rate for epoch 70 is 0.0008462999830953777
		
		Learning rate for epoch 71 is 0.0008462999830953777
		
		Learning rate for epoch 72 is 0.0008462999830953777
		
		Learning rate for epoch 73 is 0.0008462999830953777
		               loss  ParametricCrossEntropyLoss  ...  val_CRPS        lr
		epoch-1                                          ...                    
		0        734.705688                    0.439570  ...  1.042586  0.002012
		1        253.573380                    0.350318  ...  1.035599  0.002012
		2         94.463478                    0.341400  ...  1.010816  0.002012
		3         41.153385                    0.340336  ...  1.011253  0.002012
		4         20.885935                    0.309246  ...  1.007056  0.002012
		...             ...                         ...  ...       ...       ...
		68         0.830163                    0.147930  ...  0.706387  0.000846
		69         0.831098                    0.148067  ...  0.701775  0.000846
		70         0.827762                    0.148076  ...  0.702107  0.000846
		71         0.826705                    0.147443  ...  0.704216  0.000846
		72         0.827040                    0.149039  ...  0.699808  0.000846
		
		[73 rows x 9 columns]
		score = 0.18740376830101013
	train_model: completed in 1 min 20.3 s
	RAM memory: 3.248e+10
	
	Final scores:
		fold 0: 0.1466471552848816
		fold 1: 0.14995507895946503
		fold 2: 0.1082172617316246
		fold 3: 0.13993783295154572
		fold 4: 0.18740376830101013
	Average score: 0.146+/-0.025
k_fold_cross_val: completed in 7 min 10.3 s
